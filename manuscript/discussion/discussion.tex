\section{Discussion}
Here we present the results from the NCBI's Virus Discovery Hackathon. A
diverse group of international researchers met and  characterized not only
characterized the viral content in 3,000 metagenomic a subset of the SRA
datasets, and in doing so,but also identified opportunities to improve apply
bioinformatic approaches using cloud computing infrastructure and
bioinformatics research to the analysis of analyze NGS datasets. The original
intent of the hackathon was to develop an index of SRA run sets that is
searchable could be searched based on the viral content contained withinof the
runs. To that end, several use cases were identified to guide development.

The use cases developed are outlined below. 1) Identifying shared genomic
content across runs. Thus users may submit a sequence, and find all runs from
which similar contigs can be derived. 2) Filter based on run metadata. This is
essentially the same service provided by the NCBI Entrez Index. 3) Gene/Domain
based searches. Users may want to find only runs likely to encode some gene or
functional domain of interest, as determined by an analysis of contigs
assembled from the runs. 4) Searching based on virus taxonomy. A user may want
to find runs likely to contain a particular viral taxa based on an analysis of
contigs.

Despite generating a number of interesting insights, technical challenges
prevented more rapid progress. That said, we feel that these represent
opportunities for future development to enhance cloud-based bioinformatic
infrastructure and practice. While everyone involved appreciated working with
contigs, as opposed to the reads, the sheer volume of SRA data means that the
contigs do not represent enough data compression for efficient workflows. While
effort was made to identify a test data set, this data set was still perhaps
too large, as it represented nearly 55 million contigs. Thus, for future
hackathon-type events, especially if the focus is on Big Data, it is
recommended that a number of test sets be developed of various sizes, ideally
nested such that the smaller sets are subsets of the larger sets, and that they
capture the diversity of the full data set as much as is possible. Clustering
proved to be a promising data compression approach, but further work needs to
be done to both improve the efficiency of the algorithms when working at this
scale, and to determine the content of the clusters generated. Of particular
note, the large number of singletons identified are worth investigating to
determine if they represent artifacts of either the sequencing or assembly
strategies or if metagenomic data really contains such a large number of unique
sequences.

Of the classifications made, it is worth noting that the most abundant extant
virus in the data sets analyzed was crassphage (Figure 2C). While this may
reflect the preselection strategy employed (WGS metagenomic studies were
targeted), it underscores the prevalence of this recently identified virus.
Further, as seen in Figure 2B, the majority of viruses with hits to the RefSeq
virus data set were close matches to a refseq sequence (as seen by the majority
of known-known classifications). This suggests that the RefSeq set is a good
representation of extant viral sequence space. However, as seen in Figure 2A,
the majority of contigs lacked any hits to the RefSeq virus data set. This may
be due in part to the exclusion of non-viral RefSeq from the comparison.
Indeed, as seen in Figure 4B, there is likely an abundance of bacterial
sequence contained in these data sets. Still, the even larger set of sequences
with domains of unknown function supports the claim that dark matter forms a
large portion of all sequencing data. Thus, improved methods for classifying
sequences without any close hits among extant sequence space are needed.

Jupyter \cite{jupyterNotebook} was immensely popular as a framework from which
to develop work-flows and conduct exploratory analysis. However, supporting
Jupyter in the cloud is not straightforward. Simultaneously supporting
collaboration between groups, controlling access to machines, and allowing
access to data buckets is challenging. Further efforts are needed to determine
which notebook formats are best suited to the hackathon environment. Relatedly,
it was found that, when working at such a large scale, I/O remains a hurdle and
workflows developed around BigData analysis in the cloud should accommodate
this. Another challenge, felt most acutely by those working on applying machine
learning to SRA data is the need for clean metadata. When we spend time
curating datasets we should work on the ones with the most metadata, and this
should be considered when constructing test data-sets in the future.
Additionally, it was found that not all data labeled as WGS appeared to be WGS
data, emphasizing the need for better metadata documentation by the research
community. The sharing and reuse of data is one of the primary drivers behind
open, FAIR bioinformatic cyberinfrastructure \cite{Wilkinson2016}. As discussed
above, many SRA entries have incomplete metadata, which deters researchers from
performing their own analyses on other scientist’s data. Completing the
metadata would promote the reusability of data archived in NCBI’s databases.

A major goal of this work was to establish domain profiles of NGS data sets, as
these have immense potential for supporting sorting and filtering of these
massive datasets. They should be treated as first-class reference objects, and
a massive expansion of these data objects may be the most effective way to
expand into new data spaces. To this end, a follow-up hackathon is currently
being planned, during which it is hoped that progress can be made on
identifying a Jupyter framework that supports collaborative pipeline
development, and which will result in an index of at least a small portion of
the metagenomic data set available in the SRA.


\section{Conclusions}
  \begin{itemize}
    \item Conservatively assembled contigs support initial exploration of SRA data
    \item Redesigning algorithms to leverage cloud infrastructure would make
          could environments more accessible to a wider audience
    \item Approaches to classifying, and reporting the classification of,
          contigs can be effectively developed via collaboration between a
          diverse group of researchers
    \item A follow-up hackathon event is planned

  \end{itemize}
