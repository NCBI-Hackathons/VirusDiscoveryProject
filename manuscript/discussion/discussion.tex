\section{Discussion}
Here we present the results from the NCBI's Virus Discovery Hackathon. A
diverse group of international researchers met and  characterized not only
characterized the viral content in 3,000 metagenomic a subset of the SRA
datasets, and in doing so,but also identified opportunities to improve apply
bioinformatic approaches using cloud computing infrastructure and
bioinformatics research to the analysis of analyze NGS datasets. The original
intent of the hackathon was to develop an index of SRA run sets that is
searchable could be searched based on the viral content contained withinof the
runs. To that end, several use cases were identified to guide development.

The use cases developed are outlined below. 1) Identifying shared genomic
content across runs. Thus users may submit a sequence, and find all runs from
which similar contigs can be derived. 2) Filter based on run metadata. This is
essentially the same service provided by the NCBI Entrez Index. 3) Gene/Domain
based searches. Users may want to find only runs likely to encode some gene or
functional domain of interest, as determined by an analysis of contigs
assembled from the runs. 4) Searching based on virus taxonomy. A user may want
to find runs likely to contain a particular viral taxa based on an analysis of
contigs.


While the data was not quite ready to be indexed, some test data was used to
evaluate the database scheme. A full interface for user access will require
further development, but testing of particular use cases was made possible
through Python notebooks \cite{jupyterNotebook} and a collection of API
endpoints. Successful query examples were completed for multiple SRA metadata fields, and the information
could be obtained in JSON \cite{rfc_json} format or returned in tabular format
within the notebook approach. To help users who are not fluent in writing database queries
or parsing through JSON format, we made use of a PyMongoDB library to run
database lookups using python scripts. This requires the user to run the
scripts on the same machine where the database is set up, but starting from
database lookup to visualization using matplotlib or personal R scripts can all
be run on one platform - Jupyter Notebooks \cite{jupyterNotebook}. With the
complete SRA datasets, the tables will get much larger in terms of the number
of entries and the number of fields to describe each dataset. As a result, the
relationship between the tables may need to be altered.

Despite generating a number of interesting insights, technical challenges
prevented more rapid progress. That said, we feel that these represent
opportunities for future development to enhance cloud-based bioinformatic
infrastructure and practice. While everyone involved appreciated working with
contigs, as opposed to the reads, the sheer volume of SRA data means that the
contigs do not represent enough data compression for efficient workflows. While
effort was made to identify a test data set, this data set was still perhaps
too large, as it represented nearly 55 million contigs. Thus, for future
hackathon-type events, especially if the focus is on Big Data, it is
recommended that a number of test sets be developed of various sizes, ideally
nested such that the smaller sets are subsets of the larger sets, and that they
capture the diversity of the full data set as much as is possible. More
generally, developing a tool to generate subsamples from arbitrary inputs,
relevant to bioinformatic studies, may be useful, not only for testing
purposes, but also to allow estimation of how run times scale with sample size
for a given computational task or set of tasks. This in turn will support
estimating costs.

Jupyter was immensely popular as a framework from which to develop work-flows
and conduct exploratory analysis. However, supporting Jupyter in the cloud is
not straightforward. Simultaneously supporting collaboration between groups,
controlling access to machines, and allowing access to data buckets is
challenging. Further efforts are needed to determine which notebooks formats
are best suited to the hackathon environment. Relatedly, it was found that,
when working at such a large scale, I/O remains a hurdle and workflows
developed around BigData analysis in the cloud should accommodate this. Another
challenge, felt most acutely by those working on applying machine learning to
SRA data is the need for clean metadata. When we spend time curating datasets
we should work on the ones with the most metadata, and this should be
considered when constructing test data-sets in the future. Additionally, it was
found that not all data labeled as WGS appeared to be WGS data, emphasizing the
need for better metadata documentation by the research community. The sharing
and reuse of data is one of the primary drivers behind open, FAIR bioinformatic
cyberinfrastructure. As discussed above, many SRA entries have incomplete
metadata, which deters researchers from performing their own analyses on other
scientist’s data. Completing the metadata would promote the reusability of data
archived in NCBI’s databases.

A major goal of this work was to establish domain profiles of NGS data sets, as
these have immense potential for supporting sorting and filtering of these
massive datasets. They should be treated as first-class reference objects, and
a massive expansion of these data objects may be the most effective way to
expand into new data spaces. To this end, a follow-up hackathon is currently
being planned, during which it is hoped that progress can be made on
identifying a Jupyter framework that supports collaborative pipeline
development, and which will result in an index of at least a small portion of
the metagenomic data set available in the SRA.
