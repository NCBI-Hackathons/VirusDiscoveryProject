% Encoding: UTF-8

@Article{Buchfink2015,
  author          = {Buchfink, Benjamin and Xie, Chao and Huson, Daniel H},
  title           = {Fast and sensitive protein alignment using {DIAMOND}},
  journal         = {Nat. Methods},
  year            = {2015},
  volume          = {12},
  number          = {1},
  pages           = {59--60},
  month           = nov,
  issn            = {1548-7105},
  abstract        = {The alignment of sequencing reads against a protein reference database is a major computational bottleneck in metagenomics and data-intensive evolutionary projects. Although recent tools offer improved performance over the gold standard BLASTX, they exhibit only a modest speedup or low sensitivity. We introduce DIAMOND, an open-source algorithm based on double indexing that is 20,000 times faster than BLASTX on short reads and has a similar degree of sensitivity.},
  citation-subset = {IM},
  completed       = {2015-03-13},
  country         = {United States},
  created         = {2014-12-31},
  doi             = {10.1038/nmeth.3176},
  file            = {:articles-sci/Buchfink2015.pdf:PDF},
  groups          = {2019-NHMRC-Ideas, NCBI-Hack-SD},
  issn-linking    = {1548-7091},
  issue           = {1},
  keywords        = {Algorithms; Base Sequence; Humans; Metagenomics, methods; Microbiota, genetics; Sensitivity and Specificity; Sequence Alignment, methods; Sequence Analysis, DNA; Software},
  nlm-id          = {101215604},
  owner           = {NLM},
  pii             = {nmeth.3176},
  pmid            = {25402007},
  publisher       = {Springer Science and Business Media {LLC}},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2014-12-31},
  timestamp       = {2019-07-15},
  url             = {https://github.com/bbuchfink/diamond},
}

@Article{Hulo2011,
  author      = {Hulo, Chantal and {de Castro}, Edouard and Masson, Patrick and Bougueleret, Lydie and Bairoch, Amos and Xenarios, Ioannis and {Le Mercier}, Philippe},
  title       = {ViralZone: a knowledge resource to understand virus diversity.},
  journal     = {Nucleic Acids Res.},
  year        = {2011},
  volume      = {39},
  number      = {Database issue},
  pages       = {D576--D582},
  abstract    = {The molecular diversity of viruses complicates the interpretation of viral genomic and proteomic data. To make sense of viral gene functions, investigators must be familiar with the virus host range, replication cycle and virion structure. Our aim is to provide a comprehensive resource bridging together textbook knowledge with genomic and proteomic sequences. ViralZone web resource (www.expasy.org/viralzone/) provides fact sheets on all known virus families/genera with easy access to sequence data. A selection of reference strains (RefStrain) provides annotated standards to circumvent the exponential increase of virus sequences. Moreover ViralZone offers a complete set of detailed and accurate virion pictures.},
  doi         = {10.1093/nar/gkq901},
  groups      = {NCBI-Hack-SD},
  institution = {Swiss-Prot group, Swiss Institute of Bioinformatics, Centre M{\'{e}}dical Universitaire, CH-1211 Geneva 4, Switzerland.},
  keywords    = {Databases, Genetic; Genome, Viral; Genomics; Proteomics; Viral Proteins, genetics; Virion, chemistry; Virus Physiological Phenomena; Virus Replication; Viruses, classification/genetics},
  language    = {eng},
  medline-pst = {ppublish},
  owner       = {jan},
  pii         = {gkq901},
  pmid        = {20947564},
  timestamp   = {2019-07-15},
}

@Article{Shi2016,
  author       = {Mang Shi and Xian-Dan Lin and Jun-Hua Tian and Liang-Jun Chen and Xiao Chen and Ci-Xiu Li and Xin-Cheng Qin and Jun Li and Jian-Ping Cao and John-Sebastian Eden and Jan Buchmann and Wen Wang and Jianguo Xu and Edward C. Holmes and Yong-Zhen Zhang},
  title        = {Redefining the invertebrate {RNA} virosphere},
  journal      = {Nature},
  year         = {2016},
  volume       = {540},
  number       = {7634},
  pages        = {539--543},
  issn         = {1476-4687},
  abstract     = {Current knowledge of RNA virus biodiversity is both biased and fragmentary, reflecting a focus on culturable or disease-causing agents. Here we profile the transcriptomes of over 220 invertebrate species sampled across nine animal phyla and report the discovery of 1,445 RNA viruses, including some that are sufficiently divergent to comprise new families. The identified viruses fill major gaps in the RNA virus phylogeny and reveal an evolutionary history that is characterized by both host switching and co-divergence. The invertebrate virome also reveals remarkable genomic flexibility that includes frequent recombination, lateral gene transfer among viruses and hosts, gene gain and loss, and complex genomic rearrangements. Together, these data present a view of the RNA virosphere that is more phylogenetically and genomically diverse than that depicted in current classification schemes and provide a more solid foundation for studies in virus ecology and evolution.},
  country      = {England},
  created      = {2016-11-23},
  date         = {2016-11},
  doi          = {10.1038/nature20167},
  file         = {:articles-sci/Shi2016.pdf:PDF},
  groups       = {jpb, 2019-NHMRC-Ideas, NCBI-Hack-SD, publications},
  issn-linking = {0028-0836},
  journaltitle = {Nature},
  nlm-id       = {0410462},
  owner        = {NLM},
  pii          = {nature20167},
  pmid         = {27880757},
  publisher    = {Springer Nature},
  pubmodel     = {Print-Electronic},
  pubstatus    = {aheadofprint},
  revised      = {2016-12-07},
  timestamp    = {2019-07-15},
  url          = {https://doi.org/10.1038%2Fnature20167},
}

@TechReport{rfc_json,
  author      = {Tim Bray},
  title       = {The {JavaScript Object Notation (JSON)} Data Interchange Format},
  institution = {RFC Editor},
  year        = {2014},
  type        = {RFC},
  number      = {7159},
  groups      = {NCBI-Hack-SD},
  owner       = {jan},
  timestamp   = {2019-07-15},
  url         = {https://tools.ietf.org/rfc/rfc7159.txt},
}

@Article{Camacho2009,
  author          = {Camacho, Christiam and Coulouris, George and Avagyan, Vahram and Ma, Ning and Papadopoulos, Jason and Bealer, Kevin and Madden, Thomas L},
  title           = {{BLAST+}: architecture and applications.},
  journal         = {BMC Bioinf.},
  year            = {2009},
  volume          = {10},
  pages           = {421},
  month           = dec,
  issn            = {1471-2105},
  abstract        = {Sequence similarity searching is a very important bioinformatics task. While Basic Local Alignment Search Tool (BLAST) outperforms exact methods through its use of heuristics, the speed of the current BLAST software is suboptimal for very long queries or database sequences. There are also some shortcomings in the user-interface of the current command-line applications. We describe features and improvements of rewritten BLAST software and introduce new command-line applications. Long query sequences are broken into chunks for processing, in some cases leading to dramatically shorter run times. For long database sequences, it is possible to retrieve only the relevant parts of the sequence, reducing CPU time and memory usage for searches of short queries against databases of contigs or chromosomes. The program can now retrieve masking information for database sequences from the BLAST databases. A new modular software library can now access subject sequence data from arbitrary data sources. We introduce several new features, including strategy files that allow a user to save and reuse their favorite set of options. The strategy files can be uploaded to and downloaded from the NCBI BLAST web site. The new BLAST command-line applications, compared to the current BLAST tools, demonstrate substantial speed improvements for long queries as well as chromosome length database sequences. We have also improved the user interface of the command-line applications.},
  citation-subset = {IM},
  completed       = {2010-04-09},
  country         = {England},
  doi             = {10.1186/1471-2105-10-421},
  groups          = {2019-NHMRC-Ideas, NCBI-Hack-SD},
  issn-linking    = {1471-2105},
  keywords        = {Computational Biology, methods; Databases, Genetic; Sequence Alignment; Software},
  nlm-id          = {100965194},
  owner           = {jan},
  pii             = {1471-2105-10-421},
  pmc             = {PMC2803857},
  pmid            = {20003500},
  pubmodel        = {Electronic},
  pubstatus       = {epublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Gonzalez-Tortuero2018,
  author    = {Gonz{\'a}lez-Tortuero, Enrique and Sutton, Thomas DS and Velayudhan, Vimalkumar and Shkoporov, Andrey N and Draper, Lorraine A and Stockdale, Stephen R and Ross, R Paul and Hill, Colin},
  title     = {VIGA: a sensitive, precise and automatic de novo VIral Genome Annotator.},
  journal   = {bioRxiv},
  year      = {2018},
  pages     = {277509},
  doi       = {10.1101/277509},
  groups    = {2019-NHMRC-Ideas, NCBI-Hack-SD},
  owner     = {jan},
  publisher = {Cold Spring Harbor Laboratory},
  timestamp = {2019-07-15},
}

@Article{Mardis2011,
  author          = {Mardis, Elaine R},
  title           = {A decade's perspective on {DNA} sequencing technology.},
  journal         = {Nature},
  year            = {2011},
  volume          = {470},
  pages           = {198--203},
  month           = feb,
  issn            = {1476-4687},
  abstract        = {The decade since the Human Genome Project ended has witnessed a remarkable sequencing technology explosion that has permitted a multitude of questions about the genome to be asked and answered, at unprecedented speed and resolution. Here I present examples of how the resulting information has both enhanced our knowledge and expanded the impact of the genome on biomedical research. New sequencing technologies have also introduced exciting new areas of biological endeavour. The continuing upward trajectory of sequencing technology development is enabling clinical applications that are aimed at improving medical diagnosis and treatment.},
  citation-subset = {IM},
  completed       = {2011-02-28},
  country         = {England},
  doi             = {10.1038/nature09796},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {0028-0836},
  issue           = {7333},
  keywords        = {Animals; Biomedical Research, methods, trends; Genetics, Medical, methods, trends; Genome, Human, genetics; Genomics, methods, trends; Human Genome Project; Humans; Sequence Analysis, DNA, instrumentation, methods, trends},
  nlm-id          = {0410462},
  owner           = {jan},
  pii             = {nature09796},
  pmid            = {21307932},
  pubmodel        = {Print},
  pubstatus       = {ppublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Kodama2012,
  author          = {Kodama, Yuichi and Shumway, Martin and Leinonen, Rasko and {International Nucleotide Sequence Database Collaboration}},
  title           = {{The Sequence Read Archive}: explosive growth of sequencing data.},
  journal         = {Nucleic Acids Res.},
  year            = {2012},
  volume          = {40},
  pages           = {D54--D56},
  month           = jan,
  issn            = {1362-4962},
  abstract        = {New generation sequencing platforms are producing data with significantly higher throughput and lower cost. A portion of this capacity is devoted to individual and community scientific projects. As these projects reach publication, raw sequencing datasets are submitted into the primary next-generation sequence data archive, the Sequence Read Archive (SRA). Archiving experimental data is the key to the progress of reproducible science. The SRA was established as a public repository for next-generation sequence data as a part of the International Nucleotide Sequence Database Collaboration (INSDC). INSDC is composed of the National Center for Biotechnology Information (NCBI), the European Bioinformatics Institute (EBI) and the DNA Data Bank of Japan (DDBJ). The SRA is accessible at www.ncbi.nlm.nih.gov/sra from NCBI, at www.ebi.ac.uk/ena from EBI and at trace.ddbj.nig.ac.jp from DDBJ. In this article, we present the content and structure of the SRA and report on updated metadata structures, submission file formats and supported sequencing platforms. We also briefly outline our various responses to the challenge of explosive data growth.},
  citation-subset = {IM},
  completed       = {2012-07-05},
  country         = {England},
  doi             = {10.1093/nar/gkr854},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {0305-1048},
  issue           = {Database issue},
  keywords        = {Databases, Nucleic Acid; Genomics; High-Throughput Nucleotide Sequencing; Internet},
  nlm-id          = {0411011},
  owner           = {jan},
  pii             = {gkr854},
  pmc             = {PMC3245110},
  pmid            = {22009675},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Sayers2019,
  author       = {Sayers, Eric W and Agarwala, Richa and Bolton, Evan E and Brister, J Rodney and Canese, Kathi and Clark, Karen and Connor, Ryan and Fiorini, Nicolas and Funk, Kathryn and Hefferon, Timothy and Holmes, J Bradley and Kim, Sunghwan and Kimchi, Avi and Kitts, Paul A and Lathrop, Stacy and Lu, Zhiyong and Madden, Thomas L and Marchler-Bauer, Aron and Phan, Lon and Schneider, Valerie A and Schoch, Conrad L and Pruitt, Kim D and Ostell, James},
  title        = {Database resources of the {National Center for Biotechnology Information}.},
  journal      = {Nucleic Acids Res.},
  year         = {2019},
  volume       = {47},
  pages        = {D23--D28},
  month        = jan,
  issn         = {1362-4962},
  abstract     = {The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts published in life science journals. The Entrez system provides search and retrieval operations for most of these data from 38 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Augmenting many of the web applications are custom implementations of the BLAST program optimized to search specialized data sets. New resources released in the past year include PubMed Labs and a new sequence database search. Resources that were updated in the past year include PubMed, PMC, Bookshelf, genome data viewer, Assembly, prokaryotic genomes, Genome, BioProject, dbSNP, dbVar, BLAST databases, igBLAST, iCn3D and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.},
  country      = {England},
  doi          = {10.1093/nar/gky1069},
  groups       = {NCBI-Hack-SD},
  issn-linking = {0305-1048},
  issue        = {D1},
  nlm-id       = {0411011},
  owner        = {jan},
  pii          = {5160976},
  pmc          = {PMC6323993},
  pmid         = {30395293},
  pubmodel     = {Print},
  pubstatus    = {ppublish},
  revised      = {2019-01-11},
  timestamp    = {2019-07-15},
}

@Misc{StridesWeb,
  author       = {{NIH Office of Data Science Strategy}},
  title        = {{STRIDES}},
  howpublished = {Available online},
  year         = {2019},
  note         = {Accessed: 2019-07-15},
  groups       = {NCBI-Hack-SD},
  owner        = {jan},
  timestamp    = {2019-07-15},
  url          = {https://datascience.nih.gov/strides},
}

@Article{Leinonen2010,
  author          = {Leinonen, Rasko and Sugawara, Hideaki and Shumway, Martin and {International Nucleotide Sequence Database Collaboration}},
  title           = {The {Sequence Read Archive}},
  journal         = {Nucleic Acids Res.},
  year            = {2010},
  volume          = {39},
  number          = {Database},
  pages           = {D19--D21},
  month           = jan,
  issn            = {1362-4962},
  abstract        = {The combination of significantly lower cost and increased speed of sequencing has resulted in an explosive growth of data submitted into the primary next-generation sequence data archive, the Sequence Read Archive (SRA). The preservation of experimental data is an important part of the scientific record, and increasing numbers of journals and funding agencies require that next-generation sequence data are deposited into the SRA. The SRA was established as a public repository for the next-generation sequence data and is operated by the International Nucleotide Sequence Database Collaboration (INSDC). INSDC partners include the National Center for Biotechnology Information (NCBI), the European Bioinformatics Institute (EBI) and the DNA Data Bank of Japan (DDBJ). The SRA is accessible at http://www.ncbi.nlm.nih.gov/Traces/sra from NCBI, at http://www.ebi.ac.uk/ena from EBI and at http://trace.ddbj.nig.ac.jp from DDBJ. In this article, we present the content and structure of the SRA, detail our support for sequencing platforms and provide recommended data submission levels and formats. We also briefly outline our response to the challenge of data growth.},
  citation-subset = {IM},
  completed       = {2011-04-28},
  country         = {England},
  doi             = {10.1093/nar/gkq1019},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {0305-1048},
  issue           = {Database issue},
  keywords        = {Databases, Nucleic Acid; High-Throughput Nucleotide Sequencing},
  nlm-id          = {0411011},
  owner           = {jan},
  pii             = {gkq1019},
  pmc             = {PMC3013647},
  pmid            = {21062823},
  publisher       = {Oxford University Press ({OUP})},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Carroll2018,
  author          = {Carroll, Dennis and Daszak, Peter and Wolfe, Nathan D and Gao, George F and Morel, Carlos M and Morzaria, Subhash and Pablos-M{\'{e}}ndez, Ariel and Tomori, Oyewale and Mazet, Jonna A K},
  title           = {The Global Virome Project.},
  journal         = {Science (New York, N.Y.)},
  year            = {2018},
  volume          = {359},
  pages           = {872--874},
  month           = feb,
  issn            = {1095-9203},
  citation-subset = {IM},
  completed       = {2018-04-17},
  country         = {United States},
  doi             = {10.1126/science.aap7463},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {0036-8075},
  issue           = {6378},
  keywords        = {Animals; Biomedical Research, economics; Chiroptera, virology; Communicable Diseases, Emerging, epidemiology, prevention & control, virology; Disease Outbreaks, prevention & control; Host-Pathogen Interactions; Humans; Pandemics, prevention & control; Pilot Projects; Virus Diseases, epidemiology, prevention & control, virology; Viruses, genetics, isolation & purification; Zoonoses, transmission, virology},
  nlm-id          = {0404511},
  owner           = {jan},
  pii             = {359/6378/872},
  pmid            = {29472471},
  pubmodel        = {Print},
  pubstatus       = {ppublish},
  revised         = {2018-04-17},
  timestamp       = {2019-07-15},
}

@Article{Roux2015,
  author          = {Roux, Simon and Hallam, Steven J and Woyke, Tanja and Sullivan, Matthew B},
  title           = {Viral dark matter and virus-host interactions resolved from publicly available microbial genomes.},
  journal         = {eLife},
  year            = {2015},
  volume          = {4},
  month           = jul,
  issn            = {2050-084X},
  abstract        = {The ecological importance of viruses is now widely recognized, yet our limited knowledge of viral sequence space and virus-host interactions precludes accurate prediction of their roles and impacts. In this study, we mined publicly available bacterial and archaeal genomic data sets to identify 12,498 high-confidence viral genomes linked to their microbial hosts. These data augment public data sets 10-fold, provide first viral sequences for 13 new bacterial phyla including ecologically abundant phyla, and help taxonomically identify 7-38% of 'unknown' sequence space in viromes. Genome- and network-based classification was largely consistent with accepted viral taxonomy and suggested that (i) 264 new viral genera were identified (doubling known genera) and (ii) cross-taxon genomic recombination is limited. Further analyses provided empirical data on extrachromosomal prophages and coinfection prevalences, as well as evaluation of in silico virus-host linkage predictions. Together these findings illustrate the value of mining viral signal from microbial genomes. },
  citation-subset = {IM},
  completed       = {2016-04-14},
  country         = {England},
  doi             = {10.7554/eLife.08490},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {2050-084X},
  keywords        = {Archaea, genetics, virology; Bacteria, genetics, virology; Genome, Microbial; Host-Pathogen Interactions; Viruses, genetics; ecology; evolutionary biology; genomics; none; phage; prophage; virus; virus-host adaptation},
  nlm-id          = {101579614},
  owner           = {jan},
  pmc             = {PMC4533152},
  pmid            = {26200428},
  pubmodel        = {Electronic},
  pubstatus       = {epublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Souvorov2018,
  author          = {Souvorov, Alexandre and Agarwala, Richa and Lipman, David J},
  title           = {{SKESA}: strategic {k-mer} extension for scrupulous assemblies.},
  journal         = {Genome Biol.},
  year            = {2018},
  volume          = {19},
  pages           = {153},
  month           = oct,
  issn            = {1474-760X},
  abstract        = {SKESA is a DeBruijn graph-based de-novo assembler designed for assembling reads of microbial genomes sequenced using Illumina. Comparison with SPAdes and MegaHit shows that SKESA produces assemblies that have high sequence quality and contiguity, handles low-level contamination in reads, is fast, and produces an identical assembly for the same input when assembled multiple times with the same or different compute resources. SKESA has been used for assembling over 272,000 read sets in the Sequence Read Archive at NCBI and for real-time pathogen detection. Source code for SKESA is freely available at https://github.com/ncbi/SKESA/releases .},
  citation-subset = {IM},
  completed       = {2019-02-22},
  country         = {England},
  doi             = {10.1186/s13059-018-1540-z},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {1474-7596},
  issue           = {1},
  keywords        = {Algorithms; Base Pairing, genetics; Base Sequence; Sequence Analysis, DNA, methods; Software; Time Factors; Contamination; De-novo assembly; DeBruijn graphs; Illumina reads; Sequence quality},
  nlm-id          = {100960660},
  owner           = {jan},
  pii             = {10.1186/s13059-018-1540-z},
  pmc             = {PMC6172800},
  pmid            = {30286803},
  pubmodel        = {Electronic},
  pubstatus       = {epublish},
  revised         = {2019-02-22},
  timestamp       = {2019-07-15},
}

@Article{Kim2015,
  author          = {Kim, Daehwan and Langmead, Ben and Salzberg, Steven L},
  title           = {HISAT: a fast spliced aligner with low memory requirements.},
  journal         = {Nat. Methods},
  year            = {2015},
  volume          = {12},
  pages           = {357--360},
  month           = apr,
  issn            = {1548-7105},
  abstract        = {HISAT (hierarchical indexing for spliced alignment of transcripts) is a highly efficient system for aligning reads from RNA sequencing experiments. HISAT uses an indexing scheme based on the Burrows-Wheeler transform and the Ferragina-Manzini (FM) index, employing two types of indexes for alignment: a whole-genome FM index to anchor each alignment and numerous local FM indexes for very rapid extensions of these alignments. HISAT's hierarchical index for the human genome contains 48,000 local FM indexes, each representing a genomic region of ∼64,000 bp. Tests on real and simulated data sets showed that HISAT is the fastest system currently available, with equal or better accuracy than any other method. Despite its large number of indexes, HISAT requires only 4.3 gigabytes of memory. HISAT supports genomes of any size, including those larger than 4 billion bases.},
  citation-subset = {IM},
  completed       = {2015-06-25},
  country         = {United States},
  doi             = {10.1038/nmeth.3317},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {1548-7091},
  issue           = {4},
  keywords        = {Humans; Limit of Detection; Pseudogenes, genetics; Sequence Alignment, methods; Sequence Analysis, DNA, instrumentation; Sequence Analysis, RNA},
  mid             = {NIHMS736708},
  nlm-id          = {101215604},
  owner           = {jan},
  pii             = {nmeth.3317},
  pmc             = {PMC4655817},
  pmid            = {25751142},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Ondov2019,
  author    = {Ondov, Brian D and Starrett, Gabriel J and Sappington, Anna and Kostic, Aleksandra and Koren, Sergey and Buck, Christopher B and Phillippy, Adam M},
  title     = {{Mash Screen}: {High-throughput} sequence containment estimation for genome discovery},
  journal   = {BioRxiv},
  year      = {2019},
  pages     = {557314},
  month     = mar,
  doi       = {10.1101/557314},
  groups    = {NCBI-Hack-SD},
  owner     = {jan},
  publisher = {Cold Spring Harbor Laboratory},
  timestamp = {2019-07-15},
}

@Article{Enright2002,
  author          = {Enright, A J and Van Dongen, S and Ouzounis, C A},
  title           = {An efficient algorithm for large-scale detection of protein families.},
  journal         = {Nucleic Acids Res.},
  year            = {2002},
  volume          = {30},
  pages           = {1575--1584},
  month           = apr,
  issn            = {1362-4962},
  abstract        = {Detection of protein families in large databases is one of the principal research objectives in structural and functional genomics. Protein family classification can significantly contribute to the delineation of functional diversity of homologous proteins, the prediction of function based on domain architecture or the presence of sequence motifs as well as comparative genomics, providing valuable evolutionary insights. We present a novel approach called TRIBE-MCL for rapid and accurate clustering of protein sequences into families. The method relies on the Markov cluster (MCL) algorithm for the assignment of proteins into families based on precomputed sequence similarity information. This novel approach does not suffer from the problems that normally hinder other protein sequence clustering algorithms, such as the presence of multi-domain proteins, promiscuous domains and fragmented proteins. The method has been rigorously tested and validated on a number of very large databases, including SwissProt, InterPro, SCOP and the draft human genome. Our results indicate that the method is ideally suited to the rapid and accurate detection of protein families on a large scale. The method has been used to detect and categorise protein families within the draft human genome and the resulting families have been used to annotate a large proportion of human proteins.},
  chemicals       = {Proteins, Transcription Factor TFIIB, Transcription Factors},
  citation-subset = {IM},
  completed       = {2002-05-03},
  country         = {England},
  doi             = {10.1093/nar/30.7.1575},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {0305-1048},
  issue           = {7},
  keywords        = {Algorithms; Amino Acid Sequence; Databases, Protein; Genome, Human; Humans; Internet; Molecular Sequence Data; Proteins, genetics; Sequence Alignment; Sequence Homology, Amino Acid; Transcription Factor TFIIB; Transcription Factors, genetics},
  nlm-id          = {0411011},
  owner           = {jan},
  pmc             = {PMC101833},
  pmid            = {11917018},
  pubmodel        = {Print},
  pubstatus       = {ppublish},
  revised         = {2019-05-01},
  timestamp       = {2019-07-15},
}

@Article{Nawrocki2013,
  author          = {Nawrocki, Eric P and Eddy, Sean R},
  title           = {{Infernal 1.1}: 100-fold faster {RNA} homology searches.},
  journal         = {Bioinformatics (Oxford, England)},
  year            = {2013},
  volume          = {29},
  number          = {22},
  pages           = {2933--2935},
  month           = nov,
  issn            = {1367-4811},
  abstract        = {Infernal builds probabilistic profiles of the sequence and secondary structure of an RNA family called covariance models (CMs) from structurally annotated multiple sequence alignments given as input. Infernal uses CMs to search for new family members in sequence databases and to create potentially large multiple sequence alignments. Version 1.1 of Infernal introduces a new filter pipeline for RNA homology search based on accelerated profile hidden Markov model (HMM) methods and HMM-banded CM alignment methods. This enables ∼100-fold acceleration over the previous version and ∼10 000-fold acceleration over exhaustive non-filtered CM searches. Source code, documentation and the benchmark are downloadable from http://infernal.janelia.org. Infernal is freely licensed under the GNU GPLv3 and should be portable to any POSIX-compliant operating system, including Linux and Mac OS/X. Documentation includes a user's guide with a tutorial, a discussion of file formats and user options and additional details on methods implemented in the software. nawrockie@janelia.hhmi.org},
  chemicals       = {RNA},
  citation-subset = {IM},
  completed       = {2014-05-07},
  country         = {England},
  doi             = {10.1093/bioinformatics/btt509},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {1367-4803},
  issue           = {22},
  keywords        = {Algorithms; Nucleic Acid Conformation; RNA, chemistry; Sequence Alignment, methods; Sequence Analysis, RNA; Sequence Homology, Nucleic Acid; Software},
  nlm-id          = {9808944},
  owner           = {jan},
  pii             = {btt509},
  pmc             = {PMC3810854},
  pmid            = {24008419},
  publisher       = {Oxford University Press ({OUP})},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2018-12-02},
  timestamp       = {2019-07-15},
}

@Article{Grazziotin2017,
  author          = {Grazziotin, Ana Laura and Koonin, Eugene V and Kristensen, David M},
  title           = {Prokaryotic Virus Orthologous Groups ({pVOGs}): a resource for comparative genomics and protein family annotation.},
  journal         = {Nucleic Acids Res.},
  year            = {2017},
  volume          = {45},
  number          = {D1},
  pages           = {D491--D498},
  month           = jan,
  issn            = {1362-4962},
  abstract        = {Viruses are the most abundant and diverse biological entities on earth, and while most of this diversity remains completely unexplored, advances in genome sequencing have provided unprecedented glimpses into the virosphere. The Prokaryotic Virus Orthologous Groups (pVOGs, formerly called Phage Orthologous Groups, POGs) resource has aided in this task over the past decade by using automated methods to keep pace with the rapid increase in genomic data. The uses of pVOGs include functional annotation of viral proteins, identification of genes and viruses in uncharacterized DNA samples, phylogenetic analysis, large-scale comparative genomics projects, and more. The pVOGs database represents a comprehensive set of orthologous gene families shared across multiple complete genomes of viruses that infect bacterial or archaeal hosts (viruses of eukaryotes will be added at a future date). The pVOGs are constructed within the Clusters of Orthologous Groups (COGs) framework that is widely used for orthology identification in prokaryotes. Since the previous release of the POGs, the size has tripled to nearly 3000 genomes and 300 000 proteins, and the number of conserved orthologous groups doubled to 9518. User-friendly webpages are available, including multiple sequence alignments and HMM profiles for each VOG. These changes provide major improvements to the pVOGs database, at a time of rapid advances in virus genomics. The pVOGs database is hosted jointly at the University of Iowa at http://dmk-brain.ecn.uiowa.edu/pVOGs and the NCBI at ftp://ftp.ncbi.nlm.nih.gov/pub/kristensen/pVOGs/home.html.},
  chemicals       = {Viral Proteins},
  citation-subset = {IM},
  completed       = {2017-06-15},
  country         = {England},
  doi             = {10.1093/nar/gkw975},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {0305-1048},
  issue           = {D1},
  keywords        = {Computational Biology, methods; Evolution, Molecular; Genome, Viral; Genomics, methods; Molecular Sequence Annotation; Prokaryotic Cells, virology; Viral Proteins, genetics; Viruses, classification, genetics},
  nlm-id          = {0411011},
  owner           = {jan},
  pii             = {gkw975},
  pmc             = {PMC5210652},
  pmid            = {27789703},
  publisher       = {Oxford University Press ({OUP})},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Goodacre2018,
  author       = {Norman Goodacre and Aisha Aljanahi and Subhiksha Nandakumar and Mike Mikailov and Arifa S. Khan},
  title        = {A {R}eference {V}iral {D}atabase ({RVDB}) {T}o {E}nhance {B}ioinformatics {A}nalysis of {High-Throughput Sequencing} for {N}ovel {V}irus {D}etection},
  journal      = {{mSphere}},
  year         = {2018},
  volume       = {3},
  number       = {2},
  month        = mar,
  issn         = {2379-5042},
  abstract     = {Detection of distantly related viruses by high-throughput sequencing (HTS) is bioinformatically challenging because of the lack of a public database containing all viral sequences, without abundant nonviral sequences, which can extend runtime and obscure viral hits. Our reference viral database (RVDB) includes all viral, virus-related, and virus-like nucleotide sequences (excluding bacterial viruses), regardless of length, and with overall reduced cellular sequences. Semantic selection criteria (SEM-I) were used to select viral sequences from GenBank, resulting in a first-generation viral database (VDB). This database was manually and computationally reviewed, resulting in refined, semantic selection criteria (SEM-R), which were applied to a new download of updated GenBank sequences to create a second-generation VDB. Viral entries in the latter were clustered at 98% by CD-HIT-EST to reduce redundancy while retaining high viral sequence diversity. The viral identity of the clustered representative sequences (creps) was confirmed by BLAST searches in NCBI databases and HMMER searches in PFAM and DFAM databases. The resulting RVDB contained a broad representation of viral families, sequence diversity, and a reduced cellular content; it includes full-length and partial sequences and endogenous nonretroviral elements, endogenous retroviruses, and retrotransposons. Testing of RVDBv10.2, with an in-house HTS transcriptomic data set indicated a significantly faster run for virus detection than interrogating the entirety of the NCBI nonredundant nucleotide database, which contains all viral sequences but also nonviral sequences. RVDB is publically available for facilitating HTS analysis, particularly for novel virus detection. It is meant to be updated on a regular basis to include new viral sequences added to GenBank.   To facilitate bioinformatics analysis of high-throughput sequencing (HTS) data for the detection of both known and novel viruses, we have developed a new reference viral database (RVDB) that provides a broad representation of different virus species from eukaryotes by including all viral, virus-like, and virus-related sequences (excluding bacteriophages), regardless of their size. In particular, RVDB contains endogenous nonretroviral elements, endogenous retroviruses, and retrotransposons. Sequences were clustered to reduce redundancy while retaining high viral sequence diversity. A particularly useful feature of RVDB is the reduction of cellular sequences, which can enhance the run efficiency of large transcriptomic and genomic data analysis and increase the specificity of virus detection.},
  country      = {United States},
  doi          = {10.1128/mspheredirect.00069-18},
  editor       = {Michael J. Imperiale},
  groups       = {NCBI-Hack-SD},
  issn-linking = {2379-5042},
  issue        = {2},
  keywords     = {RVDB; adventitious viruses; bioinformatics analysis; high-throughput sequencing; reference virus database; viral sequences; virus detection},
  nlm-id       = {101674533},
  owner        = {jan},
  pii          = {e00069-18},
  pmc          = {PMC5853486},
  pmid         = {29564396},
  publisher    = {American Society for Microbiology},
  pubmodel     = {Electronic-eCollection},
  pubstatus    = {epublish},
  revised      = {2018-11-14},
  timestamp    = {2019-07-15},
}

@Misc{hmmer,
  author    = {Eddy, S R},
  title     = {{HMMER}: biosequence analysis using profile {hidden Markov models}},
  note      = {Accessed: 2019-07-15},
  groups    = {NCBI-Hack-SD},
  owner     = {jan},
  timestamp = {2019-07-15},
  url       = {http://hmmer.org/},
}

@Article{Torres2017,
  author          = {Torres, Pedro J and Edwards, Robert A and McNair, Katelyn A},
  title           = {{PARTIE}: a partition engine to separate metagenomic and amplicon projects in the {Sequence Read Archive}.},
  journal         = {Bioinformatics (Oxford, England)},
  year            = {2017},
  volume          = {33},
  pages           = {2389--2391},
  month           = aug,
  issn            = {1367-4811},
  abstract        = {The Sequence Read Archive (SRA) contains raw data from many different types of sequence projects. As of 2017, the SRA contained approximately ten petabases of DNA sequence (10 16 bp). Annotations of the data are provided by the submitter, and mining the data in the SRA is complicated by both the amount of data and the detail within those annotations. Here, we introduce PARTIE, a partition engine optimized to differentiate sequence read data into metagenomic (random) and amplicon (targeted) sequence data sets. PARTIE subsamples reads from the sequencing file and calculates four different statistics: k -mer frequency, 16S abundance, prokaryotic- and viral-read abundance. These metrics are used to create a RandomForest decision tree to classify the sequencing data, and PARTIE provides mechanisms for both supervised and unsupervised classification. We demonstrate the accuracy of PARTIE for classifying SRA data, discuss the probable error rates in the SRA annotations and introduce a resource assessing SRA data. PARTIE and reclassified metagenome SRA entries are available from https://github.com/linsalrob/partie. redwards@mail.sdsu.edu. Supplementary data are available at Bioinformatics online.},
  citation-subset = {IM},
  completed       = {2018-06-08},
  country         = {England},
  doi             = {10.1093/bioinformatics/btx184},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {1367-4803},
  issue           = {15},
  keywords        = {Bacteria, genetics; Humans; Metagenome; Metagenomics, methods; Microbiota, genetics; Molecular Sequence Annotation, methods; Sequence Analysis, DNA, methods; Software; Viruses, genetics},
  nlm-id          = {9808944},
  owner           = {jan},
  pii             = {3092366},
  pmc             = {PMC5860118},
  pmid            = {28369246},
  pubmodel        = {Print},
  pubstatus       = {ppublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Mirdita2019,
  author       = {Mirdita, M and Steinegger, M and S{\"{o}}ding, J},
  title        = {{MMseqs}2 desktop and local web server app for fast, interactive sequence searches.},
  journal      = {Bioinformatics (Oxford, England)},
  year         = {2019},
  month        = jan,
  issn         = {1367-4811},
  abstract     = {The MMseqs2 desktop and web server app facilitates interactive sequence searches through custom protein sequence and profile databases on personal workstations. By eliminating MMseqs2's runtime overhead, we reduced response times to a few seconds at sensitivities close to BLAST. The app is easy to install for non-experts. GPLv3-licensed code, prebuilt desktop app packages for Windows, macOS and Linux, Docker images for the web server application, and a demo web server are available at https://search.mmseqs.com. Supplementary data is available at Bioinformatics online.},
  country      = {England},
  doi          = {10.1093/bioinformatics/bty1057},
  editor       = {John Hancock},
  groups       = {NCBI-Hack-SD},
  issn-linking = {1367-4803},
  nlm-id       = {9808944},
  owner        = {jan},
  pii          = {5280135},
  pmid         = {30615063},
  publisher    = {Oxford University Press ({OUP})},
  pubmodel     = {Print-Electronic},
  pubstatus    = {aheadofprint},
  revised      = {2019-01-07},
  timestamp    = {2019-07-15},
}

@Article{Bastian2009,
  author     = {Mathieu Bastian and Sebastien Heymann and Mathieu Jacomy},
  title      = {{Gephi}: An Open Source Software for Exploring and Manipulating Networks},
  journal    = {{AAAI} Publications},
  year       = {2009},
  abstract   = {Gephi is an open source software for graph and network analysis. It uses a 3D render engine to display large networks in real-time and to speed up the exploration. A flexible and multi-task architecture brings new possibilities to work with complex data sets and produce valuable visual results.  We present several key features of Gephi in the context of interactive exploration and interpretation of networks. It provides easy and broad access to network data and allows for spatializing, filtering, navigating, manipulating and clustering. Finally, by presenting dynamic features of Gephi, we highlight key aspects of dynamic network visualization.},
  conference = {International AAAI Conference on Web and Social Media},
  groups     = {NCBI-Hack-SD},
  keywords   = {network;network science;visualization;graph exploration;open source;free software;dynamic network;interactive interface;graph;force vector;java;OpenGL;3-D visualization;user-centric;graph layout;complex graph rendering;network analysis;webatlas},
  owner      = {jan},
  timestamp  = {2019-07-15},
  url        = {https://www.aaai.org/ocs/index.php/ICWSM/09/paper/view/154},
}

@InBook{Batagelj2004,
  pages     = {77--103},
  title     = {Pajek {\textemdash} Analysis and Visualization of Large Networks},
  publisher = {Springer Berlin Heidelberg},
  year      = {2004},
  author    = {Vladimir Batagelj and Andrej Mrvar},
  editor    = {J{\"u}nger, Michael and Mutzel, Petra},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-18638-7},
  abstract  = {Pajek is a program, for Windows, for analysis and visualization of large networks having some ten or hundred of thousands of vertices. In Slovenian language pajek means spider.},
  booktitle = {Graph Drawing Software},
  doi       = {10.1007/978-3-642-18638-7_4},
  groups    = {NCBI-Hack-SD},
  owner     = {jan},
  timestamp = {2019-07-15},
  url       = {https://doi.org/10.1007/978-3-642-18638-7_4},
}

@Article{Marchler-Bauer2017,
  author          = {Marchler-Bauer, Aron and Bo, Yu and Han, Lianyi and He, Jane and Lanczycki, Christopher J and Lu, Shennan and Chitsaz, Farideh and Derbyshire, Myra K and Geer, Renata C and Gonzales, Noreen R and Gwadz, Marc and Hurwitz, David I and Lu, Fu and Marchler, Gabriele H and Song, James S and Thanki, Narmada and Wang, Zhouxi and Yamashita, Roxanne A and Zhang, Dachuan and Zheng, Chanjuan and Geer, Lewis Y and Bryant, Stephen H},
  title           = {{CDD/SPARCLE}: functional classification of proteins via subfamily domain architectures.},
  journal         = {Nucleic Acids Res.},
  year            = {2017},
  volume          = {45},
  pages           = {D200--D203},
  month           = jan,
  issn            = {1362-4962},
  abstract        = {NCBI's Conserved Domain Database (CDD) aims at annotating biomolecular sequences with the location of evolutionarily conserved protein domain footprints, and functional sites inferred from such footprints. An archive of pre-computed domain annotation is maintained for proteins tracked by NCBI's Entrez database, and live search services are offered as well. CDD curation staff supplements a comprehensive collection of protein domain and protein family models, which have been imported from external providers, with representations of selected domain families that are curated in-house and organized into hierarchical classifications of functionally distinct families and sub-families. CDD also supports comparative analyses of protein families via conserved domain architectures, and a recent curation effort focuses on providing functional characterizations of distinct subfamily architectures using SPARCLE: Subfamily Protein Architecture Labeling Engine. CDD can be accessed at https://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtml.},
  chemicals       = {Proteins},
  citation-subset = {IM},
  completed       = {2017-06-15},
  country         = {England},
  doi             = {10.1093/nar/gkw1129},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {0305-1048},
  issue           = {D1},
  keywords        = {Computational Biology, methods; Databases, Protein; Information Dissemination; Internet; Protein Interaction Domains and Motifs; Proteins, chemistry, classification, genetics},
  nlm-id          = {0411011},
  owner           = {jan},
  pii             = {gkw1129},
  pmc             = {PMC5210587},
  pmid            = {27899674},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Hyatt2010,
  author          = {Hyatt, Doug and Chen, Gwo-Liang and Locascio, Philip F and Land, Miriam L and Larimer, Frank W and Hauser, Loren J},
  title           = {Prodigal: prokaryotic gene recognition and translation initiation site identification.},
  journal         = {BMC Bioinf.},
  year            = {2010},
  volume          = {11},
  pages           = {119},
  month           = mar,
  issn            = {1471-2105},
  abstract        = {The quality of automated gene prediction in microbial organisms has improved steadily over the past decade, but there is still room for improvement. Increasing the number of correct identifications, both of genes and of the translation initiation sites for each gene, and reducing the overall number of false positives, are all desirable goals. With our years of experience in manually curating genomes for the Joint Genome Institute, we developed a new gene prediction algorithm called Prodigal (PROkaryotic DYnamic programming Gene-finding ALgorithm). With Prodigal, we focused specifically on the three goals of improved gene structure prediction, improved translation initiation site recognition, and reduced false positives. We compared the results of Prodigal to existing gene-finding methods to demonstrate that it met each of these objectives. We built a fast, lightweight, open source gene prediction program called Prodigal http://compbio.ornl.gov/prodigal/. Prodigal achieved good results compared to existing methods, and we believe it will be a valuable asset to automated microbial annotation pipelines.},
  citation-subset = {IM},
  completed       = {2010-05-11},
  country         = {England},
  doi             = {10.1186/1471-2105-11-119},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {1471-2105},
  keywords        = {Algorithms; Databases, Genetic; Genome, Bacterial; Peptide Chain Initiation, Translational, genetics; Prokaryotic Cells; Software},
  nlm-id          = {100965194},
  owner           = {jan},
  pii             = {1471-2105-11-119},
  pmc             = {PMC2848648},
  pmid            = {20211023},
  pubmodel        = {Electronic},
  pubstatus       = {epublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Hildebrand2009,
  author          = {Hildebrand, Andrea and Remmert, Michael and Biegert, Andreas and S{\"{o}}ding, Johannes},
  title           = {Fast and accurate automatic structure prediction with {HHpred}.},
  journal         = {Proteins},
  year            = {2009},
  volume          = {77 Suppl 9},
  pages           = {128--132},
  issn            = {1097-0134},
  abstract        = {Automated protein structure prediction is becoming a mainstream tool for biological research. This has been fueled by steady improvements of publicly available automated servers over the last decade, in particular their ability to build good homology models for an increasing number of targets by reliably detecting and aligning more and more remotely homologous templates. Here, we describe the three fully automated versions of the HHpred server that participated in the community-wide blind protein structure prediction competition CASP8. What makes HHpred unique is the combination of usability, short response times (typically under 15 min) and a model accuracy that is competitive with those of the best servers in CASP8.},
  chemicals       = {Proteins},
  citation-subset = {IM},
  completed       = {2010-01-19},
  country         = {United States},
  doi             = {10.1002/prot.22499},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {0887-3585},
  keywords        = {Computational Biology, methods; Protein Conformation; Proteins, chemistry; Sequence Alignment, methods; Sequence Analysis, Protein, methods; Software},
  nlm-id          = {8700181},
  owner           = {jan},
  pmid            = {19626712},
  pubmodel        = {Print},
  pubstatus       = {ppublish},
  revised         = {2009-10-29},
  timestamp       = {2019-07-15},
}

@Article{Zhu2013,
  author          = {Zhu, Yuelin and Stephens, Robert M and Meltzer, Paul S and Davis, Sean R},
  title           = {{SRAdb}: query and use public next-generation sequencing data from within {R}.},
  journal         = {BMC Bioinf.},
  year            = {2013},
  volume          = {14},
  pages           = {19},
  month           = jan,
  issn            = {1471-2105},
  abstract        = {The Sequence Read Archive (SRA) is the largest public repository of sequencing data from the next generation of sequencing platforms including Illumina (Genome Analyzer, HiSeq, MiSeq, .etc), Roche 454 GS System, Applied Biosystems SOLiD System, Helicos Heliscope, PacBio RS, and others. SRAdb is an attempt to make queries of the metadata associated with SRA submission, study, sample, experiment and run more robust and precise, and make access to sequencing data in the SRA easier. We have parsed all the SRA metadata into a SQLite database that is routinely updated and can be easily distributed. The SRAdb R/Bioconductor package then utilizes this SQLite database for querying and accessing metadata. Full text search functionality makes querying metadata very flexible and powerful. Fastq files associated with query results can be downloaded easily for local analysis. The package also includes an interface from R to a popular genome browser, the Integrated Genomics Viewer. SRAdb Bioconductor package provides a convenient and integrated framework to query and access SRA metadata quickly and powerfully from within R.},
  citation-subset = {IM},
  completed       = {2013-09-18},
  country         = {England},
  doi             = {10.1186/1471-2105-14-19},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {1471-2105},
  keywords        = {Databases, Nucleic Acid; Genomics, methods; High-Throughput Nucleotide Sequencing, methods; Software},
  nlm-id          = {100965194},
  owner           = {jan},
  pii             = {1471-2105-14-19},
  pmc             = {PMC3560148},
  pmid            = {23323543},
  pubmodel        = {Electronic},
  pubstatus       = {epublish},
  revised         = {2018-12-02},
  timestamp       = {2019-07-15},
}

@Article{Le2014,
  author      = {Quoc V. Le and Tomas Mikolov},
  title       = {Distributed Representations of Sentences and Documents},
  journal     = {{arXiv} e-prints},
  year        = {2014},
  abstract    = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
  date        = {2014-05-16},
  eprint      = {http://arxiv.org/abs/1405.4053v2},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1405.4053v2:PDF},
  groups      = {NCBI-Hack-SD},
  keywords    = {cs.CL, cs.AI, cs.LG},
  owner       = {jan},
  timestamp   = {2019-07-15},
}

@Article{vanDerMaaten2008,
  author    = {van der Maaten, Laurens and Hinton, Geoffrey},
  title     = {Visualizing Data using {t-SNE}},
  journal   = {Journal of Machine Learning Research},
  year      = {2008},
  volume    = {9},
  pages     = {2579--2605},
  added-at  = {2015-06-19T12:07:15.000+0200},
  biburl    = {https://www.bibsonomy.org/bibtex/28b9aebb404ad4a4c6a436ea413550b30/lopusz_kdd},
  groups    = {NCBI-Hack-SD},
  interhash = {370ba8b9e1909b61880a6f47c93bcd49},
  intrahash = {8b9aebb404ad4a4c6a436ea413550b30},
  keywords  = {dimensionality_reduction tSNE visualization},
  owner     = {jan},
  timestamp = {2019-07-15},
  url       = {http://www.jmlr.org/papers/v9/vandermaaten08a.html},
}

@Article{Brister2015,
  author          = {Brister, J Rodney and Ako-Adjei, Danso and Bao, Yiming and Blinkova, Olga},
  title           = {NCBI viral genomes resource.},
  journal         = {Nucleic Acids Res.},
  year            = {2015},
  volume          = {43},
  pages           = {D571--D577},
  month           = jan,
  issn            = {1362-4962},
  abstract        = {Recent technological innovations have ignited an explosion in virus genome sequencing that promises to fundamentally alter our understanding of viral biology and profoundly impact public health policy. Yet, any potential benefits from the billowing cloud of next generation sequence data hinge upon well implemented reference resources that facilitate the identification of sequences, aid in the assembly of sequence reads and provide reference annotation sources. The NCBI Viral Genomes Resource is a reference resource designed to bring order to this sequence shockwave and improve usability of viral sequence data. The resource can be accessed at http://www.ncbi.nlm.nih.gov/genome/viruses/ and catalogs all publicly available virus genome sequences and curates reference genome sequences. As the number of genome sequences has grown, so too have the difficulties in annotating and maintaining reference sequences. The rapid expansion of the viral sequence universe has forced a recalibration of the data model to better provide extant sequence representation and enhanced reference sequence products to serve the needs of the various viral communities. This, in turn, has placed increased emphasis on leveraging the knowledge of individual scientific communities to identify important viral sequences and develop well annotated reference virus genome sets. },
  citation-subset = {IM},
  completed       = {2015-06-29},
  country         = {England},
  doi             = {10.1093/nar/gku1207},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {0305-1048},
  issue           = {Database issue},
  keywords        = {Databases, Nucleic Acid; Genome, Viral; High-Throughput Nucleotide Sequencing; Internet; Molecular Sequence Annotation; Software; Viruses, classification},
  nlm-id          = {0411011},
  owner           = {jan},
  pii             = {gku1207},
  pmc             = {PMC4383986},
  pmid            = {25428358},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2018-11-13},
  timestamp       = {2019-07-15},
}

@Article{Shean2019,
  author          = {Shean, Ryan C and Makhsous, Negar and Stoddard, Graham D and Lin, Michelle J and Greninger, Alexander L},
  title           = {{VAPiD}: a lightweight cross-platform viral annotation pipeline and identification tool to facilitate virus genome submissions to {NCBI} {GenBank}.},
  journal         = {BMC Bioinf.},
  year            = {2019},
  volume          = {20},
  pages           = {48},
  month           = jan,
  issn            = {1471-2105},
  abstract        = {With sequencing technologies becoming cheaper and easier to use, more groups are able to obtain whole genome sequences of viruses of public health and scientific importance. Submission of genomic data to NCBI GenBank is a requirement prior to publication and plays a critical role in making scientific data publicly available. GenBank currently has automatic prokaryotic and eukaryotic genome annotation pipelines but has no viral annotation pipeline beyond influenza virus. Annotation and submission of viral genome sequence is a non-trivial task, especially for groups that do not routinely interact with GenBank for data submissions. We present Viral Annotation Pipeline and iDentification (VAPiD), a portable and lightweight command-line tool for annotation and GenBank deposition of viral genomes. VAPiD supports annotation of nearly all unsegmented viral genomes. The pipeline has been validated on human immunodeficiency virus, human parainfluenza virus 1-4, human metapneumovirus, human coronaviruses (229E/OC43/NL63/HKU1/SARS/MERS), human enteroviruses/rhinoviruses, measles virus, mumps virus, Hepatitis A-E Virus, Chikungunya virus, dengue virus, and West Nile virus, as well the human polyomaviruses BK/JC/MCV, human adenoviruses, and human papillomaviruses. The program can handle individual or batch submissions of different viruses to GenBank and correctly annotates multiple viruses, including those that contain ribosomal slippage or RNA editing without prior knowledge of the virus to be annotated. VAPiD is programmed in Python and is compatible with Windows, Linux, and Mac OS systems. We have created a portable, lightweight, user-friendly, internet-enabled, open-source, command-line genome annotation and submission package to facilitate virus genome submissions to NCBI GenBank. Instructions for downloading and installing VAPiD can be found at https://github.com/rcs333/VAPiD .},
  citation-subset = {IM},
  completed       = {2019-03-04},
  country         = {England},
  doi             = {10.1186/s12859-019-2606-y},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {1471-2105},
  issue           = {1},
  keywords        = {Databases, Nucleic Acid, standards; Genome, Viral, genetics; Genomics, methods; Humans; Data submission; GenBank; NCBI; VAPiD; Viral annotation; Viral genomics; Virus sequence},
  nlm-id          = {100965194},
  owner           = {jan},
  pii             = {10.1186/s12859-019-2606-y},
  pmc             = {PMC6343335},
  pmid            = {30674273},
  pubmodel        = {Electronic},
  pubstatus       = {epublish},
  revised         = {2019-03-04},
  timestamp       = {2019-07-15},
}

@Article{Alves2018,
  author       = {Alves, Luana de F{\'{a}}tima and Westmann, Cau{\~{a}} Antunes and Lovate, Gabriel Lencioni and de Siqueira, Guilherme Marcelino Viana and Borelli, Tiago Cabral and Guazzaroni, Mar{\'{i}}a-Eugenia},
  title        = {Metagenomic Approaches for Understanding New Concepts in Microbial Science.},
  journal      = {Int J Plant Genomics},
  year         = {2018},
  volume       = {2018},
  pages        = {2312987},
  issn         = {2314-436X},
  abstract     = {Over the past thirty years, since the dawn of metagenomic studies, a completely new (micro) universe was revealed, with the potential to have profound impacts on many aspects of the society. Remarkably, the study of human microbiome provided a new perspective on a myriad of human traits previously regarded as solely (epi-) genetically encoded, such as disease susceptibility, immunological response, and social and nutritional behaviors. In this context, metagenomics has established a powerful framework for understanding the intricate connections between human societies and microbial communities, ultimately allowing for the optimization of both human health and productivity. Thus, we have shifted from the old concept of microbes as harmful organisms to a broader panorama, in which the signal of the relationship between humans and microbes is flexible and directly dependent on our own decisions and practices. In parallel, metagenomics has also been playing a major role in the prospection of "hidden" genetic features and the development of biotechnological applications, through the discovery of novel genes, enzymes, pathways, and bioactive molecules with completely new or improved biochemical functions. Therefore, this review highlights the major milestones over the last three decades of metagenomics, providing insights into both its potentialities and current challenges.},
  country      = {United States},
  doi          = {10.1155/2018/2312987},
  groups       = {NCBI-Hack-SD},
  issn-linking = {2314-436X},
  nlm-id       = {101605206},
  owner        = {jan},
  pmc          = {PMC6126073},
  pmid         = {30211213},
  pubmodel     = {Electronic-eCollection},
  pubstatus    = {epublish},
  revised      = {2018-11-14},
  timestamp    = {2019-07-15},
}

@Misc{jupyterNotebook,
  author       = {{Jupyter Steering Council}},
  title        = {The {Jupyter/IPython Project}},
  howpublished = {Online},
  note         = {Accessed: 2019-07-15},
  groups       = {NCBI-Hack-SD},
  owner        = {jan},
  timestamp    = {2019-07-15},
  url          = {https://jupyter.org/},
}

@Article{Choi2018,
  author          = {Illyoung Choi and Alise J Ponsero and Matthew Bomhoff and Ken Youens-Clark and John H Hartman and Bonnie L Hurwitz},
  title           = {Libra: scalable k-mer-based tool for massive all-vs-all metagenome comparisons.},
  journal         = {{GigaScience}},
  year            = {2018},
  volume          = {8},
  number          = {2},
  month           = dec,
  issn            = {2047-217X},
  __markedentry   = {[jan:6]},
  abstract        = {Shotgun metagenomics provides powerful insights into microbial community biodiversity and function. Yet, inferences from metagenomic studies are often limited by dataset size and complexity and are restricted by the availability and completeness of existing databases. De novo comparative metagenomics enables the comparison of metagenomes based on their total genetic content. We developed a tool called Libra that performs an all-vs-all comparison of metagenomes for precise clustering based on their k-mer content. Libra uses a scalable Hadoop framework for massive metagenome comparisons, Cosine Similarity for calculating the distance using sequence composition and abundance while normalizing for sequencing depth, and a web-based implementation in iMicrobe (http://imicrobe.us) that uses the CyVerse advanced cyberinfrastructure to promote broad use of the tool by the scientific community. A comparison of Libra to equivalent tools using both simulated and real metagenomic datasets, ranging from 80 million to 4.2 billion reads, reveals that methods commonly implemented to reduce compute time for large datasets, such as data reduction, read count normalization, and presence/absence distance metrics, greatly diminish the resolution of large-scale comparative analyses. In contrast, Libra uses all of the reads to calculate k-mer abundance in a Hadoop architecture that can scale to any size dataset to enable global-scale analyses and link microbial signatures to biological processes.},
  citation-subset = {IM},
  completed       = {2019-06-24},
  country         = {United States},
  doi             = {10.1093/gigascience/giy165},
  groups          = {NCBI-Hack-SD},
  issn-linking    = {2047-217X},
  issue           = {2},
  keywords        = {Algorithms; Cluster Analysis; High-Throughput Nucleotide Sequencing, methods; Metagenomics, methods; Microbiota, genetics; Sequence Analysis, DNA, methods; Software},
  nlm-id          = {101596872},
  owner           = {jan},
  pii             = {5266304},
  pmc             = {PMC6354030},
  pmid            = {30597002},
  publisher       = {Oxford University Press ({OUP})},
  pubmodel        = {Electronic},
  pubstatus       = {epublish},
  revised         = {2019-06-24},
  timestamp       = {2019-07-15},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectory-jan-salk:/home/jan/library/jabref;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:NCBI-Hack-SD\;0\;1\;\;\;\;;
1 StaticGroup:2019-NHMRC-Ideas\;0\;1\;\;\;\;;
1 StaticGroup:jpb\;0\;1\;\;\;\;;
2 StaticGroup:talks\;0\;1\;\;\;\;;
2 StaticGroup:poster\;0\;1\;\;\;\;;
2 StaticGroup:publications\;0\;1\;\;\;\;;
1 StaticGroup:WIP\;0\;1\;\;\;\;;
}

@Comment{jabref-meta: saveActions:enabled;
date[normalize_date]
editor[unicode_to_latex]
pages[normalize_page_numbers]
journal[unicode_to_latex]
month[normalize_month]
author[unicode_to_latex]
all-text-fields[ordinals_to_superscript]
title[html_to_latex,unicode_to_latex]
booktitle[unicode_to_latex]
;}
