\section{Materials and Methods}

  \subsection{Participant Recruitment}
  After initial conception of this project by BB, RJ (JRB?) and RE, RE offered
  to provide a venue for an international hackathon.  Participants were
  recruited through the outreach efforts of BB, RJ, and RE.  VZ identified
  datasets, which were then parsed by RE using PARTIE \cite{Torres2017} to look
  at any potential amplicon or 16S character.  The resulting set of SRRs can be
  found in \url{https://github.com/NCBI-Hackathons/VirusDiscoveryProject/blob/master/DataSelection/hackathon.sets}.

  \subsection{Assembling contigs from metagenomic datasets (pre-Hackathon)}
  Contigs containing putative virus sequences were assembled from metagenomic
  SRA datasets by removing human reads and assembling putative virus sequences
  into contigs using SKESA \cite{Souvorov2018}. All reads from an SRR archive
  were aligned against the human genome reference sequence (GRCh38.p12) using
  HISAT2 \cite{Kim2015} (see the associated github repository for execution
  details, \url{https://github.com/NCBI-Hackathons/VirusDiscoveryProject}).
  Reads mapping fully or partially  to the human genome were  classified as
  'human'. Putative virus sequences in the remaining reads were identified
  using a K-mer taxonomy approach (NCBI, unpublished). The remaining NCBI
  taxonomy identifiers were used to extract sequences from Refseq. Given that
  some viruses are overrepresented in RefSeq,  only a few per species were
  selected at random while for viruses with segmented genomes, e.g. Influenza,
  all sequences were selected and deduplicated by k-mer distances in a later
  step using MASH \cite{Ondov2019}. Putative virus reads were assembled using
  the guided\_assembler from the SKESA and these contigs obtained identifiers
  based on the guide accessions with a sequential index as a suffix, for
  example NC\_006883.2\_1 is based on Prochlorococcus phage genome
  NC\_006883.2.In cases where guide selection failed to detect good reference
  sets a default viral reference set was used based on the ViralZone database
  \cite{Hulo2011}.


  Reads not classified as virus or human were de-novo assembled with SKESA. For
  the assembled runs the de novo contigs served as a reference set to align the
  reads with HISAT2 (as above). The reads that didn't align onto either human,
  viral or de-novo contigs were classified as unknown. As a result of the
  workflow each run was re-aligned onto human, viral and de-novo contigs and
  contains the same set of reads as the original run. The alignments were
  converted into SRA format without quality scores and stored in google cloud
  storage for later analysis. Given that most SRA metagenomic reads are
  bacterial or of unknown origin this step was the most computationally
  intensive with significant memory and runtime requirements. Due to the
  limited budget a timeout was introduced on de-novo assembly step and some
  runs failed to complete.

  \subsection{Domain mapping}
  Contigs that were classified by BLASTn as unknown-unknowns, were inspected
  for domain content using RPSTBPASTN \cite{Camacho2009}. Briefly, the protein
  domains from the Conserved Domain Database (CDD) \cite{Marchler-Bauer2017}  were
  downloaded and split into 32 different databases, to benefit most from the
  available threads. RPSTBLASTN searches were ran with an E-value cut-off of
  $1e^{-3}$, and the output was generated in JSON format. A working example and the
  commands used are available on GitHub under
  \url{https://github.com/NCBI-Hackathons/VirusDiscoveryProject/tree/master/DomainLabeling/example}

  \subsection{Megablast}
  Contigs and Refseq virus nucleotide sequences were stored in a single flat
  file. Coding-complete, genomic viral sequences were extracted from the NCBI
  Entrez Nucleotide database
  (\url{https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?VirusLineage_ss=Viruses,%20taxid:10239&SeqType_s=Nucleotide})
  to create a specific database  using the makeblastdb command-line tool
  \cite{Camacho2009}. All sequences were compared against  all sequences using
  MEGABLAST \cite{Camacho2009} with an E-value cut-off of $1e^{-10}$ and a
  maximum of one contiguously-aligned region (High-scoring Segment pair, HSP)
  per query-subject pair.

  \subsection{Markov Clustering}
  Markov Clustering (MCL) \cite{Enright2002} was applied to blast results as
  outlined in the associated documentation (\url{https://micans.org/mcl}).
  Briefly, tabular blast output was modified to include only qacc, sacc, and
  E-value columns, and passed to mcxload to generate network and dictionary
  files. Thus the set of query and subject pairs is treated as the edge set for
  a graph, the associated E-values are treated as edge weights. The
  stream-mirror argument was used to ensure the network is undirected, and
  stream-neg-log10  and stream-tf 'ceil(200)' arguments were used to log
  transform E-values, setting a maximum value of 200 for edge weights. Finally,
  the mcl algorithm was run on the loaded network with an inflation value of
  10, and 32 threads. All MCL work was performed on a Google Cloud Platform
  (GCP) machine with 96 cores and 240 Gb RAM.

  \subsection{VIGA}
  Modifications were made to the standard VIGA \cite{Gonzalez-Tortuero2018}
  protocol to enhance the overall speed of the program, removing the rRNA
  detection step by INFERNAL \cite{Nawrocki2013}. This pipeline handled this
  information, enhancing the identification of viral specific hidden-Markov
  models (HMM) annotations by the utilization of the complete pVOG database
  \cite{Grazziotin2017} (9,518 HMMs) and the addition of RVDB
  \cite{Goodacre2018} using HMMER suite \cite{hmmer}. Modified scripts and
  instructions to reproduce all steps are available on GitHub at
  \url{https://github.com/NCBI-Hackathons/VirusDiscoveryProject/tree/master/VirusGenes}.
  All viral annotation was performed on a GCP machine with 96 cores and 350 Gb
  RAM

  \subsection{Machine Learning}
  Jaccard distance was estimated on the identified viral contigs using MASH
  \cite{Ondov2019}, a technique shown to be a reliable tool to cluster amplicon
  datasets, metagenome read datasets and contig datasets \cite{Choi2018}. A
  kmer size of 21 bp was chosen with a sketch size of 10,000. Samples
  containing less than two viral contigs were removed from the analysis. A
  total of 511 samples were kept for the analyzed and clustered by ward
  clustering. A manual cleaning of the terms was performed to remove
  punctuation and low-informative terms. In total, 210 samples with abstract
  and comments were analyzed.
